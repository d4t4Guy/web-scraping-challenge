{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies:\n",
    "import pandas as pd\n",
    "import time #allows for sleep method. To-Do: Research if there is a method that doesn't require an additional module\n",
    "from bs4 import BeautifulSoup #html parser\n",
    "import pymongo #allows direct interaction with mongo db through Python\n",
    "\n",
    "#required for splinter (To-Do: need to verify splinter dependencies)\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from splinter import Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 89.0.4389\n",
      "[WDM] - Get LATEST driver version for 89.0.4389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\Test\\.wdm\\drivers\\chromedriver\\win32\\89.0.4389.23\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "#create driver\n",
    "executable_path = {'executable_path':ChromeDriverManager().install()}  #To-do: continue searching for more efficient method\n",
    "#set up browser\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "#path provided by instruction\n",
    "news_path = 'https://mars.nasa.gov/news/'\n",
    "browser.visit(news_path)\n",
    "time.sleep(3)\n",
    "html = browser.html\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#use bs4 to parse the title and paragraph\n",
    "soup=BeautifulSoup(html, 'html.parser') #returns a soup object\n",
    "news_title = soup.find('h3', class_='').text #works correctly 2021-03-17.\n",
    "# Observation that most recent news article headline is under the first \n",
    "# <h3> tag with no CSS class assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find first slide, which represents most recent news story. Then find\n",
    "# a div tag with class_ = \"article_teaser_body\" within that \n",
    "\n",
    "news_paragraph =soup.find('li', class_='slide') \\\n",
    "                    .find('div', class_=\"article_teaser_body\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA's Mars Helicopter to Make First Flight Attempt Sunday \n",
      " The small rotorcraft’s “Wright brothers moment” is two Mars days away.\n"
     ]
    }
   ],
   "source": [
    "print(f'{news_title} \\n {news_paragraph}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Syntax example from bs4 docs\n",
    "# for link in soup.find_all('a'):\n",
    "#     print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up browser, seems to need to be redone after a browser.quit()\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "gallery_url = 'https://www.jpl.nasa.gov/images?search=&category=Mars'  #pulled from readme.md instructions\n",
    "\n",
    "browser.visit(gallery_url)\n",
    "time.sleep(5)\n",
    "html = browser.html\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(html, 'html.parser') #returns a soup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/images/australe-mensa-false-color'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div', class_=\"SearchResultCard\").find('a', class_=\"group cursor-pointer block\").get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_photo_url = 'https://jpl.nasa.gov'+soup.find('div', class_=\"SearchResultCard\").find('a', class_=\"group cursor-pointer block\").get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "browser.visit(top_photo_url)\n",
    "time.sleep(5)\n",
    "html = browser.html\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find \"Download JPG \" (trailing space included) label and get preceding href, which should be the full size photo\n",
    "featured_image_url = soup.find(string='Download JPG ').find_previous('a').get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://d2pn8kiwq2w21t.cloudfront.net/original_images/jpegPIA24556.jpg\n"
     ]
    }
   ],
   "source": [
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_facts_url = 'https://www.space-facts.com/mars/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "browser.visit(mars_facts_url)\n",
    "# time.sleep(3)\n",
    "html = browser.html\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#snippet from: https://stackoverflow.com/questions/23377533/python-beautifulsoup-parsing-table retrieved 2021-03-24\n",
    "\n",
    "labels = []\n",
    "points = []\n",
    "\n",
    "table = soup.find('table', class_='tablepress tablepress-id-p-mars')\n",
    "table_body = table.find('tbody')\n",
    "rows = table_body.find_all('tr')\n",
    "for row in rows:\n",
    "    cols=row.find_all('td', class_='column-1')\n",
    "    for col in cols:\n",
    "        txt = col.get_text()\n",
    "        labels.append(txt)\n",
    "    \n",
    "    cols=row.find_all('td', class_='column-2')\n",
    "    for col in cols:\n",
    "        txt = col.get_text()\n",
    "        points.append(txt)\n",
    "\n",
    "df = pd.DataFrame({'Mars':points}, index=labels)\n",
    "html_table = df.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls = [\n",
    "    {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg\"},\n",
    "    {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg\"},\n",
    "    {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg\"},\n",
    "    {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg\"},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_dict = {}\n",
    "scrape_dict['news_headline'] = news_title\n",
    "scrape_dict['news_teaser']   = news_paragraph\n",
    "scrape_dict['featured_image_url'] = featured_image_url\n",
    "scrape_dict['html_table'] = html_table\n",
    "scrape_dict['hemisphere_image_urls'] = hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn string\n",
    "mongo_conn= 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(mongo_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database and collection\n",
    "    #deprecated these two lines\n",
    "    #db = client.mars_db\n",
    "    #collection = db.items\n",
    "collection = client.mars_app.mars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x26cd3516a00>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dump the dict into mongo as a document\n",
    "collection.insert_one(scrape_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape = client.mars_app.mars.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count_documents({}) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for record in scrape:\n",
    "    print(record)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
